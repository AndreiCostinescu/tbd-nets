{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to run TbD-net through test data on the CLEVR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from tbd.module_net import load_tbd_net\n",
    "from utils.clevr import load_vocab\n",
    "from utils.generate_programs import load_program_generator, generate_programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained model we want to produce test answers for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_path = Path('data/vocab.json')\n",
    "model_path = Path('models/clevr-reg-hres.pt')\n",
    "tbd_net = load_tbd_net(model_path, load_vocab(vocab_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate, we first need to generate programs from the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program_generator = load_program_generator(Path('models/program_generator.pt'))\n",
    "generate_programs(Path('data/test/test_questions.h5'), program_generator, \n",
    "                  dest_dir=Path('data/test/'), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test features that we've extracted and the the questions, image indices, and programs we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_np_features = True\n",
    "if use_np_features:\n",
    "    features = np.load(Path('data/test/features.npy'), mmap_mode='r')\n",
    "else:\n",
    "    features = h5py.File(Path('data/test/features.h5'))['features']\n",
    "\n",
    "question_np = np.load(Path('data/test/questions.npy'))\n",
    "image_idx_np = np.load(Path('data/test/image_idxs.npy'))\n",
    "programs_np = np.load(Path('data/test/programs.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mapping from our model output to answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = ['blue', 'brown', 'cyan', 'gray', 'green', 'purple', 'red', 'yellow',\n",
    "           'cube', 'cylinder', 'sphere',\n",
    "           'large', 'small',\n",
    "           'metal', 'rubber',\n",
    "           'no', 'yes',\n",
    "           '0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "pred_idx_to_token = dict(zip(range(len(answers)), answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience function for writing predictions to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('predicted_answers.txt', 'w')\n",
    "def write_preds(preds):\n",
    "    for pred in preds:\n",
    "        f.write(pred)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that wraps `torch.autograd.Variable` to use the GPU when CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Variable(tensor):\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return torch.autograd.Variable(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through all of the questions, produce a prediction, and write that predicted answer to the text file we opened above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "for batch in range(int(len(programs_np) / 128 + 0.5)):\n",
    "    image_idx = image_idx_np[batch_size*batch:batch_size*(batch+1)]\n",
    "    programs = torch.LongTensor(programs_np[batch_size*batch:batch_size*(batch+1)])\n",
    "    \n",
    "    if use_np_features:\n",
    "        feats = torch.FloatTensor(np.asarray(features[image_idx]))\n",
    "    else:\n",
    "        # Using HDF5 files requires some overhead due to constraints on how those may\n",
    "        # be accessed. We cannot index into the file using a numpy array. We also cannot \n",
    "        # access the same element multiple times (e.g. we cannot index into an h5py.File \n",
    "        # with [1,1,1]) because we are constrained to increasing sequences\n",
    "        image_idx = image_idx_np[batch_size*batch:batch_size*(batch+1)]\n",
    "        feats = []\n",
    "        for idx in image_idx:\n",
    "            feats.append(np.asarray(features[idx]))\n",
    "        feats = torch.FloatTensor(np.asarray(feats))\n",
    "\n",
    "    feats_var = Variable(feats)\n",
    "    programs_var = Variable(programs)\n",
    "    outputs = tbd_net(feats_var, programs_var)\n",
    "    _, preds = outputs.max(1)\n",
    "    preds = [pred_idx_to_token[pred] for pred in preds.data.cpu().numpy()]\n",
    "    write_preds(preds)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
